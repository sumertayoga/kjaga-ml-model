{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback (tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95 and logs.get('val_accuracy')>0.95):\n",
    "            print(\"\\nReached 85% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    mobilenet_v3 = \"https://www.kaggle.com/models/google/mobilenet-v3/frameworks/TensorFlow2/variations/small-100-224-feature-vector/versions/1\"\n",
    "    mobile_net_layers = hub.KerasLayer(mobilenet_v3, input_shape=(224,224,3))\n",
    "    mobile_net_layers.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        mobile_net_layers,\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(22,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    train_dir = '../data/training/'\n",
    "    validation_dir = '../data/validation/'\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255.,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255.\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        batch_size=5,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        batch_size=5,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    callback = myCallback()\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callback\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    mobilenet_v3 = tf.keras.applications.MobileNetV3Small(input_shape=(224,224,3), include_top=False)\n",
    "\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        mobilenet_v3,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    train_dir = '../data3/training/'\n",
    "    validation_dir = '../data3/validation/'\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255.,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255.\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        batch_size=5,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        batch_size=5,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    callback = myCallback()\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=300,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callback\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 576)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5770      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 944,890\n",
      "Trainable params: 932,778\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n",
      "Found 398 images belonging to 10 classes.\n",
      "Found 135 images belonging to 10 classes.\n",
      "Epoch 1/300\n",
      "80/80 [==============================] - 11s 66ms/step - loss: 3.2139 - accuracy: 0.0930 - val_loss: 2.3674 - val_accuracy: 0.0889\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 3.0145 - accuracy: 0.0879 - val_loss: 2.3631 - val_accuracy: 0.0889\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 2.8334 - accuracy: 0.0779 - val_loss: 2.3588 - val_accuracy: 0.0889\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 2.7025 - accuracy: 0.1080 - val_loss: 2.3447 - val_accuracy: 0.0889\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 2.6010 - accuracy: 0.1382 - val_loss: 2.3401 - val_accuracy: 0.0889\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 2.5078 - accuracy: 0.1508 - val_loss: 2.3418 - val_accuracy: 0.0963\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 2.4675 - accuracy: 0.1709 - val_loss: 2.3569 - val_accuracy: 0.1556\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 2.3626 - accuracy: 0.1608 - val_loss: 2.3800 - val_accuracy: 0.1111\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 2.3242 - accuracy: 0.1683 - val_loss: 2.4045 - val_accuracy: 0.1333\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 2.2826 - accuracy: 0.1683 - val_loss: 2.4208 - val_accuracy: 0.1333\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 2.2249 - accuracy: 0.2010 - val_loss: 2.4331 - val_accuracy: 0.1333\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 2.1881 - accuracy: 0.2035 - val_loss: 2.4504 - val_accuracy: 0.1333\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 2.1529 - accuracy: 0.2312 - val_loss: 2.4771 - val_accuracy: 0.1333\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 2.0543 - accuracy: 0.2613 - val_loss: 2.5060 - val_accuracy: 0.1333\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 2.0448 - accuracy: 0.2688 - val_loss: 2.5336 - val_accuracy: 0.1333\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 2.0140 - accuracy: 0.2864 - val_loss: 2.5648 - val_accuracy: 0.1333\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 2.0313 - accuracy: 0.2538 - val_loss: 2.5967 - val_accuracy: 0.1333\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 1.9936 - accuracy: 0.2889 - val_loss: 2.6321 - val_accuracy: 0.1333\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 1.9399 - accuracy: 0.3065 - val_loss: 2.6444 - val_accuracy: 0.1333\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 1.9185 - accuracy: 0.3065 - val_loss: 2.6336 - val_accuracy: 0.1333\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 1.8348 - accuracy: 0.3417 - val_loss: 2.6349 - val_accuracy: 0.1333\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.7689 - accuracy: 0.3970 - val_loss: 2.6652 - val_accuracy: 0.1333\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.8084 - accuracy: 0.3618 - val_loss: 2.7215 - val_accuracy: 0.0815\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 1.7098 - accuracy: 0.3844 - val_loss: 2.7792 - val_accuracy: 0.0593\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.7362 - accuracy: 0.3719 - val_loss: 2.7870 - val_accuracy: 0.0667\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.6951 - accuracy: 0.4397 - val_loss: 2.8085 - val_accuracy: 0.0593\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.7070 - accuracy: 0.4296 - val_loss: 2.8359 - val_accuracy: 0.0593\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.6991 - accuracy: 0.4372 - val_loss: 2.8918 - val_accuracy: 0.0593\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.6022 - accuracy: 0.4673 - val_loss: 2.9528 - val_accuracy: 0.0593\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.5427 - accuracy: 0.4698 - val_loss: 3.0453 - val_accuracy: 0.0593\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.5057 - accuracy: 0.4724 - val_loss: 3.0864 - val_accuracy: 0.0593\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 1.4847 - accuracy: 0.5050 - val_loss: 3.1017 - val_accuracy: 0.0593\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.5616 - accuracy: 0.5050 - val_loss: 3.1395 - val_accuracy: 0.0593\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.4431 - accuracy: 0.5025 - val_loss: 3.2425 - val_accuracy: 0.0593\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.4396 - accuracy: 0.5352 - val_loss: 3.3576 - val_accuracy: 0.0593\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.3640 - accuracy: 0.5553 - val_loss: 3.4695 - val_accuracy: 0.0593\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.3234 - accuracy: 0.5704 - val_loss: 3.4990 - val_accuracy: 0.0593\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.3789 - accuracy: 0.5528 - val_loss: 3.5621 - val_accuracy: 0.0593\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.2990 - accuracy: 0.5829 - val_loss: 3.6066 - val_accuracy: 0.0593\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.2811 - accuracy: 0.5678 - val_loss: 3.6507 - val_accuracy: 0.0593\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.2936 - accuracy: 0.5879 - val_loss: 3.6787 - val_accuracy: 0.0593\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.3204 - accuracy: 0.5879 - val_loss: 3.6684 - val_accuracy: 0.0593\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.2370 - accuracy: 0.5754 - val_loss: 3.6293 - val_accuracy: 0.0593\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.2520 - accuracy: 0.5905 - val_loss: 3.5430 - val_accuracy: 0.0667\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.1703 - accuracy: 0.6055 - val_loss: 3.4369 - val_accuracy: 0.0667\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.2370 - accuracy: 0.5854 - val_loss: 3.2718 - val_accuracy: 0.0741\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.2087 - accuracy: 0.6030 - val_loss: 3.0838 - val_accuracy: 0.0889\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.1451 - accuracy: 0.6307 - val_loss: 2.8943 - val_accuracy: 0.1037\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.1639 - accuracy: 0.5955 - val_loss: 2.7422 - val_accuracy: 0.1259\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.0998 - accuracy: 0.6583 - val_loss: 2.6210 - val_accuracy: 0.1556\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.1046 - accuracy: 0.6332 - val_loss: 2.4917 - val_accuracy: 0.1704\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 1.0828 - accuracy: 0.6382 - val_loss: 2.3807 - val_accuracy: 0.1852\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.0187 - accuracy: 0.6859 - val_loss: 2.3250 - val_accuracy: 0.1926\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.0536 - accuracy: 0.6734 - val_loss: 2.2374 - val_accuracy: 0.2074\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.0698 - accuracy: 0.6382 - val_loss: 2.1620 - val_accuracy: 0.2148\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 1.0057 - accuracy: 0.6457 - val_loss: 2.1075 - val_accuracy: 0.2074\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.0350 - accuracy: 0.6457 - val_loss: 2.0605 - val_accuracy: 0.2444\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.9563 - accuracy: 0.6709 - val_loss: 2.0452 - val_accuracy: 0.2667\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.0002 - accuracy: 0.6734 - val_loss: 2.0284 - val_accuracy: 0.2593\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.0342 - accuracy: 0.6357 - val_loss: 2.0056 - val_accuracy: 0.2519\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.9579 - accuracy: 0.6709 - val_loss: 1.9893 - val_accuracy: 0.2519\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.9695 - accuracy: 0.6709 - val_loss: 1.9542 - val_accuracy: 0.2667\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.9271 - accuracy: 0.6583 - val_loss: 1.9294 - val_accuracy: 0.2815\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.9237 - accuracy: 0.6960 - val_loss: 1.9226 - val_accuracy: 0.2889\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.9615 - accuracy: 0.6407 - val_loss: 1.9059 - val_accuracy: 0.3037\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8962 - accuracy: 0.6809 - val_loss: 1.8553 - val_accuracy: 0.3185\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.9173 - accuracy: 0.6608 - val_loss: 1.8070 - val_accuracy: 0.3333\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.8509 - accuracy: 0.7211 - val_loss: 1.7881 - val_accuracy: 0.3630\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.7924 - accuracy: 0.7286 - val_loss: 1.7749 - val_accuracy: 0.3630\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.9142 - accuracy: 0.6759 - val_loss: 1.7740 - val_accuracy: 0.3778\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.7714 - accuracy: 0.7312 - val_loss: 1.7253 - val_accuracy: 0.4000\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.8779 - accuracy: 0.7136 - val_loss: 1.7338 - val_accuracy: 0.3704\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.8040 - accuracy: 0.7261 - val_loss: 1.6810 - val_accuracy: 0.4074\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8710 - accuracy: 0.7261 - val_loss: 1.6349 - val_accuracy: 0.4074\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8565 - accuracy: 0.7161 - val_loss: 1.5687 - val_accuracy: 0.4222\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8783 - accuracy: 0.7010 - val_loss: 1.5242 - val_accuracy: 0.4296\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8805 - accuracy: 0.7010 - val_loss: 1.4497 - val_accuracy: 0.4741\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.8097 - accuracy: 0.7312 - val_loss: 1.4028 - val_accuracy: 0.5037\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.7656 - accuracy: 0.7387 - val_loss: 1.3519 - val_accuracy: 0.5481\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.7808 - accuracy: 0.7085 - val_loss: 1.3304 - val_accuracy: 0.5407\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.8025 - accuracy: 0.7337 - val_loss: 1.2975 - val_accuracy: 0.5481\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8400 - accuracy: 0.7060 - val_loss: 1.2534 - val_accuracy: 0.5778\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.8356 - accuracy: 0.7186 - val_loss: 1.1777 - val_accuracy: 0.5852\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.7181 - accuracy: 0.7487 - val_loss: 1.1151 - val_accuracy: 0.6074\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.7726 - accuracy: 0.7412 - val_loss: 1.0821 - val_accuracy: 0.6444\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.7867 - accuracy: 0.7362 - val_loss: 1.0355 - val_accuracy: 0.6519\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.7578 - accuracy: 0.7462 - val_loss: 0.9925 - val_accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.7592 - accuracy: 0.7588 - val_loss: 0.9447 - val_accuracy: 0.6963\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.6853 - accuracy: 0.7688 - val_loss: 0.9096 - val_accuracy: 0.6963\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.7594 - accuracy: 0.7261 - val_loss: 0.8678 - val_accuracy: 0.7333\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.7352 - accuracy: 0.7362 - val_loss: 0.8241 - val_accuracy: 0.7333\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.7515 - accuracy: 0.7437 - val_loss: 0.7866 - val_accuracy: 0.7333\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6919 - accuracy: 0.7638 - val_loss: 0.7706 - val_accuracy: 0.7333\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.7102 - accuracy: 0.7588 - val_loss: 0.7444 - val_accuracy: 0.7407\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.7197 - accuracy: 0.7462 - val_loss: 0.7029 - val_accuracy: 0.7704\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.7314 - accuracy: 0.7538 - val_loss: 0.6706 - val_accuracy: 0.7926\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.7137 - accuracy: 0.7487 - val_loss: 0.6402 - val_accuracy: 0.7926\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.6591 - accuracy: 0.7613 - val_loss: 0.6437 - val_accuracy: 0.7926\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.6628 - accuracy: 0.7663 - val_loss: 0.6425 - val_accuracy: 0.7926\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6634 - accuracy: 0.7663 - val_loss: 0.7666 - val_accuracy: 0.7111\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.7224 - accuracy: 0.7538 - val_loss: 0.7405 - val_accuracy: 0.7333\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6167 - accuracy: 0.7739 - val_loss: 0.7037 - val_accuracy: 0.7333\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.7052 - accuracy: 0.7613 - val_loss: 0.6584 - val_accuracy: 0.7630\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6787 - accuracy: 0.7714 - val_loss: 0.6100 - val_accuracy: 0.8000\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6079 - accuracy: 0.8065 - val_loss: 0.5816 - val_accuracy: 0.8148\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6682 - accuracy: 0.7839 - val_loss: 0.5482 - val_accuracy: 0.8148\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6751 - accuracy: 0.7814 - val_loss: 0.5115 - val_accuracy: 0.8148\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.6530 - accuracy: 0.7538 - val_loss: 0.4753 - val_accuracy: 0.8222\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5858 - accuracy: 0.8216 - val_loss: 0.4521 - val_accuracy: 0.8370\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6069 - accuracy: 0.7764 - val_loss: 0.4532 - val_accuracy: 0.8370\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6694 - accuracy: 0.7940 - val_loss: 0.4451 - val_accuracy: 0.8593\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.6782 - accuracy: 0.7814 - val_loss: 0.4342 - val_accuracy: 0.8519\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6190 - accuracy: 0.8015 - val_loss: 0.4228 - val_accuracy: 0.8519\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6242 - accuracy: 0.7915 - val_loss: 0.4285 - val_accuracy: 0.8593\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.5791 - accuracy: 0.8317 - val_loss: 0.4205 - val_accuracy: 0.8519\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6127 - accuracy: 0.7915 - val_loss: 0.4214 - val_accuracy: 0.8444\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5521 - accuracy: 0.8141 - val_loss: 0.4214 - val_accuracy: 0.8519\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.5346 - accuracy: 0.8241 - val_loss: 0.3951 - val_accuracy: 0.8444\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.5170 - accuracy: 0.8216 - val_loss: 0.4009 - val_accuracy: 0.8593\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6119 - accuracy: 0.7864 - val_loss: 0.4110 - val_accuracy: 0.8667\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6497 - accuracy: 0.7814 - val_loss: 0.3933 - val_accuracy: 0.8741\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5808 - accuracy: 0.7889 - val_loss: 0.3957 - val_accuracy: 0.8741\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.5551 - accuracy: 0.8065 - val_loss: 0.3780 - val_accuracy: 0.8667\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5776 - accuracy: 0.8317 - val_loss: 0.4120 - val_accuracy: 0.8667\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.5327 - accuracy: 0.8015 - val_loss: 0.3958 - val_accuracy: 0.8815\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.5567 - accuracy: 0.8191 - val_loss: 0.3879 - val_accuracy: 0.8815\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5343 - accuracy: 0.8040 - val_loss: 0.3941 - val_accuracy: 0.8815\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5288 - accuracy: 0.8090 - val_loss: 0.4002 - val_accuracy: 0.8815\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.4519 - accuracy: 0.8643 - val_loss: 0.3894 - val_accuracy: 0.8815\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 0.4935 - accuracy: 0.8291 - val_loss: 0.3570 - val_accuracy: 0.8741\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5196 - accuracy: 0.8141 - val_loss: 0.3542 - val_accuracy: 0.8815\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5456 - accuracy: 0.8191 - val_loss: 0.3648 - val_accuracy: 0.8815\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.5687 - accuracy: 0.7915 - val_loss: 0.3853 - val_accuracy: 0.8741\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.5672 - accuracy: 0.8065 - val_loss: 0.3727 - val_accuracy: 0.8889\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4592 - accuracy: 0.8543 - val_loss: 0.3530 - val_accuracy: 0.8963\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.4836 - accuracy: 0.8266 - val_loss: 0.3459 - val_accuracy: 0.8963\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.5304 - accuracy: 0.8166 - val_loss: 0.3293 - val_accuracy: 0.9037\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4260 - accuracy: 0.8593 - val_loss: 0.3279 - val_accuracy: 0.9111\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.5534 - accuracy: 0.8191 - val_loss: 0.3281 - val_accuracy: 0.9037\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.4895 - accuracy: 0.8417 - val_loss: 0.3130 - val_accuracy: 0.9037\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5057 - accuracy: 0.8367 - val_loss: 0.3127 - val_accuracy: 0.9037\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.5217 - accuracy: 0.8291 - val_loss: 0.3019 - val_accuracy: 0.9111\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.5109 - accuracy: 0.8090 - val_loss: 0.3062 - val_accuracy: 0.9037\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5489 - accuracy: 0.8166 - val_loss: 0.3921 - val_accuracy: 0.8815\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5130 - accuracy: 0.8266 - val_loss: 0.3913 - val_accuracy: 0.8815\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5212 - accuracy: 0.8166 - val_loss: 0.3632 - val_accuracy: 0.8889\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4311 - accuracy: 0.8392 - val_loss: 0.3674 - val_accuracy: 0.8889\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4063 - accuracy: 0.8668 - val_loss: 0.3988 - val_accuracy: 0.8815\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5155 - accuracy: 0.8216 - val_loss: 0.4217 - val_accuracy: 0.8815\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4432 - accuracy: 0.8442 - val_loss: 0.4258 - val_accuracy: 0.8667\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5201 - accuracy: 0.8442 - val_loss: 0.4143 - val_accuracy: 0.8741\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4445 - accuracy: 0.8618 - val_loss: 0.4064 - val_accuracy: 0.8741\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4674 - accuracy: 0.8392 - val_loss: 0.4069 - val_accuracy: 0.8667\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.5013 - accuracy: 0.8342 - val_loss: 0.4297 - val_accuracy: 0.8444\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.4164 - accuracy: 0.8618 - val_loss: 0.3991 - val_accuracy: 0.8593\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4338 - accuracy: 0.8568 - val_loss: 0.3712 - val_accuracy: 0.8889\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.4787 - accuracy: 0.8593 - val_loss: 0.3436 - val_accuracy: 0.8963\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4876 - accuracy: 0.8216 - val_loss: 0.3535 - val_accuracy: 0.8889\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4675 - accuracy: 0.8467 - val_loss: 0.3542 - val_accuracy: 0.8741\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4092 - accuracy: 0.8568 - val_loss: 0.3555 - val_accuracy: 0.8815\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.4778 - accuracy: 0.8342 - val_loss: 0.3262 - val_accuracy: 0.8963\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4533 - accuracy: 0.8543 - val_loss: 0.3153 - val_accuracy: 0.8963\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4683 - accuracy: 0.8417 - val_loss: 0.2927 - val_accuracy: 0.9037\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4727 - accuracy: 0.8241 - val_loss: 0.2793 - val_accuracy: 0.9111\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.5006 - accuracy: 0.8317 - val_loss: 0.2639 - val_accuracy: 0.9111\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4537 - accuracy: 0.8442 - val_loss: 0.2585 - val_accuracy: 0.9111\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.5225 - accuracy: 0.8116 - val_loss: 0.2518 - val_accuracy: 0.9111\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3624 - accuracy: 0.8844 - val_loss: 0.2542 - val_accuracy: 0.9111\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4740 - accuracy: 0.8417 - val_loss: 0.2460 - val_accuracy: 0.9185\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4069 - accuracy: 0.8593 - val_loss: 0.2528 - val_accuracy: 0.9185\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4010 - accuracy: 0.8744 - val_loss: 0.2472 - val_accuracy: 0.9259\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.4060 - accuracy: 0.8618 - val_loss: 0.2615 - val_accuracy: 0.9111\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.4536 - accuracy: 0.8492 - val_loss: 0.2500 - val_accuracy: 0.9259\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4572 - accuracy: 0.8291 - val_loss: 0.2448 - val_accuracy: 0.9259\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.4199 - accuracy: 0.8442 - val_loss: 0.2461 - val_accuracy: 0.9259\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4334 - accuracy: 0.8693 - val_loss: 0.2454 - val_accuracy: 0.9259\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.4151 - accuracy: 0.8593 - val_loss: 0.2520 - val_accuracy: 0.9185\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4263 - accuracy: 0.8543 - val_loss: 0.2478 - val_accuracy: 0.9259\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3837 - accuracy: 0.8719 - val_loss: 0.2506 - val_accuracy: 0.9185\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.3873 - accuracy: 0.8744 - val_loss: 0.2581 - val_accuracy: 0.9185\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3533 - accuracy: 0.8869 - val_loss: 0.2420 - val_accuracy: 0.9111\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3449 - accuracy: 0.8794 - val_loss: 0.2673 - val_accuracy: 0.9037\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.4518 - accuracy: 0.8317 - val_loss: 0.2912 - val_accuracy: 0.9037\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4862 - accuracy: 0.8417 - val_loss: 0.2761 - val_accuracy: 0.9037\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4475 - accuracy: 0.8417 - val_loss: 0.2556 - val_accuracy: 0.9037\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3685 - accuracy: 0.8719 - val_loss: 0.2440 - val_accuracy: 0.9259\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3769 - accuracy: 0.8744 - val_loss: 0.2426 - val_accuracy: 0.9185\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4569 - accuracy: 0.8417 - val_loss: 0.2332 - val_accuracy: 0.9185\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4222 - accuracy: 0.8568 - val_loss: 0.2406 - val_accuracy: 0.9111\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3261 - accuracy: 0.8844 - val_loss: 0.2235 - val_accuracy: 0.9407\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4513 - accuracy: 0.8467 - val_loss: 0.2258 - val_accuracy: 0.9259\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3457 - accuracy: 0.8794 - val_loss: 0.2277 - val_accuracy: 0.9259\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.4089 - accuracy: 0.8568 - val_loss: 0.2287 - val_accuracy: 0.9111\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3917 - accuracy: 0.8668 - val_loss: 0.2370 - val_accuracy: 0.9111\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3970 - accuracy: 0.8693 - val_loss: 0.2159 - val_accuracy: 0.9333\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3721 - accuracy: 0.8744 - val_loss: 0.2113 - val_accuracy: 0.9407\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3757 - accuracy: 0.8819 - val_loss: 0.2038 - val_accuracy: 0.9333\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3820 - accuracy: 0.8769 - val_loss: 0.2030 - val_accuracy: 0.9407\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3506 - accuracy: 0.8769 - val_loss: 0.2023 - val_accuracy: 0.9407\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.3126 - accuracy: 0.8920 - val_loss: 0.2014 - val_accuracy: 0.9407\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3365 - accuracy: 0.8744 - val_loss: 0.2070 - val_accuracy: 0.9407\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3457 - accuracy: 0.8869 - val_loss: 0.2122 - val_accuracy: 0.9407\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3734 - accuracy: 0.8668 - val_loss: 0.2145 - val_accuracy: 0.9259\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3888 - accuracy: 0.8618 - val_loss: 0.2049 - val_accuracy: 0.9333\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2939 - accuracy: 0.9171 - val_loss: 0.2045 - val_accuracy: 0.9259\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.4132 - accuracy: 0.8819 - val_loss: 0.2107 - val_accuracy: 0.9333\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3169 - accuracy: 0.8744 - val_loss: 0.2168 - val_accuracy: 0.9259\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3817 - accuracy: 0.8844 - val_loss: 0.2169 - val_accuracy: 0.9259\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.4454 - accuracy: 0.8417 - val_loss: 0.2147 - val_accuracy: 0.9407\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3686 - accuracy: 0.8668 - val_loss: 0.2105 - val_accuracy: 0.9185\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3837 - accuracy: 0.8794 - val_loss: 0.2020 - val_accuracy: 0.9259\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.3267 - accuracy: 0.8894 - val_loss: 0.2044 - val_accuracy: 0.9111\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3231 - accuracy: 0.8995 - val_loss: 0.2046 - val_accuracy: 0.9037\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.3429 - accuracy: 0.8819 - val_loss: 0.1939 - val_accuracy: 0.9111\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3200 - accuracy: 0.8945 - val_loss: 0.1877 - val_accuracy: 0.9259\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3002 - accuracy: 0.8995 - val_loss: 0.1862 - val_accuracy: 0.9185\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3657 - accuracy: 0.8894 - val_loss: 0.1862 - val_accuracy: 0.9407\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.3171 - accuracy: 0.8995 - val_loss: 0.1861 - val_accuracy: 0.9407\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3148 - accuracy: 0.8819 - val_loss: 0.1769 - val_accuracy: 0.9407\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3401 - accuracy: 0.8869 - val_loss: 0.1762 - val_accuracy: 0.9407\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3478 - accuracy: 0.8744 - val_loss: 0.1747 - val_accuracy: 0.9407\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3234 - accuracy: 0.8970 - val_loss: 0.1781 - val_accuracy: 0.9407\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3412 - accuracy: 0.8970 - val_loss: 0.1753 - val_accuracy: 0.9333\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.4032 - accuracy: 0.8618 - val_loss: 0.1714 - val_accuracy: 0.9407\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.3115 - accuracy: 0.8894 - val_loss: 0.1804 - val_accuracy: 0.9333\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3360 - accuracy: 0.8970 - val_loss: 0.1798 - val_accuracy: 0.9630\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2744 - accuracy: 0.9196 - val_loss: 0.1819 - val_accuracy: 0.9630\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2494 - accuracy: 0.9271 - val_loss: 0.1870 - val_accuracy: 0.9481\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2774 - accuracy: 0.9121 - val_loss: 0.1950 - val_accuracy: 0.9407\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.3395 - accuracy: 0.8920 - val_loss: 0.1881 - val_accuracy: 0.9407\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3467 - accuracy: 0.8945 - val_loss: 0.1770 - val_accuracy: 0.9481\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2722 - accuracy: 0.9045 - val_loss: 0.1767 - val_accuracy: 0.9481\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.3032 - accuracy: 0.9121 - val_loss: 0.1735 - val_accuracy: 0.9481\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3337 - accuracy: 0.8869 - val_loss: 0.1702 - val_accuracy: 0.9333\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2530 - accuracy: 0.9171 - val_loss: 0.1681 - val_accuracy: 0.9333\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2844 - accuracy: 0.8995 - val_loss: 0.1669 - val_accuracy: 0.9333\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2715 - accuracy: 0.8995 - val_loss: 0.1664 - val_accuracy: 0.9333\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2506 - accuracy: 0.9271 - val_loss: 0.1847 - val_accuracy: 0.9185\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2939 - accuracy: 0.8970 - val_loss: 0.1945 - val_accuracy: 0.9111\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2541 - accuracy: 0.9095 - val_loss: 0.1981 - val_accuracy: 0.9111\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.2717 - accuracy: 0.9095 - val_loss: 0.2003 - val_accuracy: 0.9185\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2749 - accuracy: 0.9020 - val_loss: 0.2066 - val_accuracy: 0.9259\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2222 - accuracy: 0.9271 - val_loss: 0.1844 - val_accuracy: 0.9259\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.3097 - accuracy: 0.9095 - val_loss: 0.1876 - val_accuracy: 0.9259\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.2782 - accuracy: 0.9095 - val_loss: 0.1956 - val_accuracy: 0.9259\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3629 - accuracy: 0.8819 - val_loss: 0.2310 - val_accuracy: 0.9185\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2723 - accuracy: 0.9171 - val_loss: 0.1963 - val_accuracy: 0.9333\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.3093 - accuracy: 0.8995 - val_loss: 0.1837 - val_accuracy: 0.9333\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2443 - accuracy: 0.9221 - val_loss: 0.1695 - val_accuracy: 0.9259\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2423 - accuracy: 0.9171 - val_loss: 0.1635 - val_accuracy: 0.9556\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2310 - accuracy: 0.9372 - val_loss: 0.1648 - val_accuracy: 0.9481\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2808 - accuracy: 0.9121 - val_loss: 0.1847 - val_accuracy: 0.9333\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3057 - accuracy: 0.8995 - val_loss: 0.1989 - val_accuracy: 0.9185\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3119 - accuracy: 0.8819 - val_loss: 0.1935 - val_accuracy: 0.9259\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2193 - accuracy: 0.9296 - val_loss: 0.2068 - val_accuracy: 0.9185\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2583 - accuracy: 0.9146 - val_loss: 0.2040 - val_accuracy: 0.9185\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.2631 - accuracy: 0.9221 - val_loss: 0.2140 - val_accuracy: 0.9185\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2166 - accuracy: 0.9372 - val_loss: 0.1768 - val_accuracy: 0.9259\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2739 - accuracy: 0.9121 - val_loss: 0.1633 - val_accuracy: 0.9259\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.2720 - accuracy: 0.9146 - val_loss: 0.1602 - val_accuracy: 0.9333\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.3069 - accuracy: 0.8945 - val_loss: 0.2101 - val_accuracy: 0.9185\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.3183 - accuracy: 0.8920 - val_loss: 0.2188 - val_accuracy: 0.9259\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2723 - accuracy: 0.9146 - val_loss: 0.1937 - val_accuracy: 0.9259\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.2613 - accuracy: 0.9196 - val_loss: 0.1755 - val_accuracy: 0.9259\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.2774 - accuracy: 0.9146 - val_loss: 0.1757 - val_accuracy: 0.9185\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2398 - accuracy: 0.9196 - val_loss: 0.1922 - val_accuracy: 0.9333\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2622 - accuracy: 0.9171 - val_loss: 0.1902 - val_accuracy: 0.9111\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2817 - accuracy: 0.9121 - val_loss: 0.2187 - val_accuracy: 0.9037\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.2657 - accuracy: 0.9196 - val_loss: 0.2005 - val_accuracy: 0.9185\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2698 - accuracy: 0.9146 - val_loss: 0.2136 - val_accuracy: 0.9111\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2601 - accuracy: 0.9146 - val_loss: 0.1970 - val_accuracy: 0.9037\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2575 - accuracy: 0.9221 - val_loss: 0.1842 - val_accuracy: 0.9185\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2198 - accuracy: 0.9347 - val_loss: 0.1887 - val_accuracy: 0.9111\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2251 - accuracy: 0.9196 - val_loss: 0.1847 - val_accuracy: 0.9185\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.2275 - accuracy: 0.9246 - val_loss: 0.2029 - val_accuracy: 0.9111\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.2992 - accuracy: 0.8970 - val_loss: 0.1994 - val_accuracy: 0.9185\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2912 - accuracy: 0.9121 - val_loss: 0.1906 - val_accuracy: 0.9185\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2896 - accuracy: 0.9146 - val_loss: 0.1811 - val_accuracy: 0.9259\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2527 - accuracy: 0.9171 - val_loss: 0.1946 - val_accuracy: 0.9259\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2325 - accuracy: 0.9196 - val_loss: 0.1676 - val_accuracy: 0.9407\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3187 - accuracy: 0.9020 - val_loss: 0.1584 - val_accuracy: 0.9630\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2162 - accuracy: 0.9296 - val_loss: 0.1564 - val_accuracy: 0.9630\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2548 - accuracy: 0.9221 - val_loss: 0.1663 - val_accuracy: 0.9630\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.2599 - accuracy: 0.9221 - val_loss: 0.1619 - val_accuracy: 0.9704\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.2073 - accuracy: 0.9472 - val_loss: 0.1583 - val_accuracy: 0.9481\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2631 - accuracy: 0.9121 - val_loss: 0.1606 - val_accuracy: 0.9481\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2469 - accuracy: 0.9171 - val_loss: 0.1616 - val_accuracy: 0.9556\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.3105 - accuracy: 0.9196 - val_loss: 0.1591 - val_accuracy: 0.9407\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2265 - accuracy: 0.9347 - val_loss: 0.1523 - val_accuracy: 0.9704\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2460 - accuracy: 0.9246 - val_loss: 0.1511 - val_accuracy: 0.9556\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2722 - accuracy: 0.8970 - val_loss: 0.1509 - val_accuracy: 0.9481\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2408 - accuracy: 0.9196 - val_loss: 0.1591 - val_accuracy: 0.9407\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.1854 - accuracy: 0.9447 - val_loss: 0.1568 - val_accuracy: 0.9481\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.2295 - accuracy: 0.9221 - val_loss: 0.1543 - val_accuracy: 0.9407\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.1976 - accuracy: 0.9347 - val_loss: 0.1594 - val_accuracy: 0.9481\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.2303 - accuracy: 0.9322 - val_loss: 0.1642 - val_accuracy: 0.9407\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.1971 - accuracy: 0.9372 - val_loss: 0.1634 - val_accuracy: 0.9481\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.2506 - accuracy: 0.9246 - val_loss: 0.1550 - val_accuracy: 0.9333\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.1879 - accuracy: 0.9472 - val_loss: 0.1518 - val_accuracy: 0.9481\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.1741 - accuracy: 0.9472 - val_loss: 0.1471 - val_accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.save(\"./model.v1-5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[4.8728272e-01 9.9262718e+01 8.1784159e-02 1.3537657e-01 1.6016125e-03\n",
      "  4.8219943e-03 1.3671792e-03 8.3298981e-04 7.7417870e-03 1.6467793e-02]]\n",
      "The predicted class is: 1\n",
      "The predicted food is: Ayam Goreng\n"
     ]
    }
   ],
   "source": [
    "# Specify the local image path\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "\n",
    "local_image_path = '../data3/validation/Ayam Goreng/20210605215357-1-ilustrasi-ayam-sasando-001-tantri-setyorini.jpg'\n",
    "\n",
    "# Make predictions for the local image\n",
    "img = image.load_img(local_image_path, target_size=(224, 224))  # Adjust target_size as needed\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "img_array = img_array/255.\n",
    "\n",
    "# Make predictions\n",
    "train_dir = \"../data3/training/\"\n",
    "classes = [f for f in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, f))]\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions * 100)\n",
    "\n",
    "predicted_class = np.argmax(predictions)\n",
    "predicted_food = classes[predicted_class]\n",
    "\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "print(f\"The predicted food is: {predicted_food}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
